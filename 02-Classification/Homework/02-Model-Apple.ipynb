{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "pd.set_option('display.max_columns', None)  \n",
    "\n",
    "import sys, os, yaml\n",
    "\n",
    "DATASET = \"Apple-Quality\"\n",
    "COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "DEBUG = False\n",
    "SEED = 666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if COLAB:\n",
    "  from google.colab import drive\n",
    "  if not os.path.isdir(\"/content/gdrive\"):\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    d = \"/content/gdrive/MyDrive/datasets\"\n",
    "    if not os.path.isdir(ROOT+d): os.makedirs(ROOT+d)\n",
    "  ROOT = f\"/content/gdrive/MyDrive/datasets/{DATASET.replace(' ','_')}/\"\n",
    "  if not os.path.isdir(ROOT): os.makedirs(ROOT)\n",
    "else:\n",
    "  ROOT = \"./\"\n",
    "\n",
    "def makedirs(d):\n",
    "  if COLAB:\n",
    "    if not os.path.isdir(ROOT+d): os.makedirs(ROOT+d)\n",
    "  else:\n",
    "    if not os.path.isdir(ROOT+d): os.makedirs(ROOT+d, mode=0o777, exist_ok=True)\n",
    "\n",
    "for d in ['orig','data','output']: makedirs(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"{ROOT}/data/apple.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Size</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Sweetness</th>\n",
       "      <th>Crunchiness</th>\n",
       "      <th>Juiciness</th>\n",
       "      <th>Ripeness</th>\n",
       "      <th>Acidity</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.970049</td>\n",
       "      <td>-2.512336</td>\n",
       "      <td>5.346330</td>\n",
       "      <td>-1.012009</td>\n",
       "      <td>1.844900</td>\n",
       "      <td>0.329840</td>\n",
       "      <td>-0.491590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.195217</td>\n",
       "      <td>-2.839257</td>\n",
       "      <td>3.664059</td>\n",
       "      <td>1.588232</td>\n",
       "      <td>0.853286</td>\n",
       "      <td>0.867530</td>\n",
       "      <td>-0.722809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.292024</td>\n",
       "      <td>-1.351282</td>\n",
       "      <td>-1.738429</td>\n",
       "      <td>-0.342616</td>\n",
       "      <td>2.838636</td>\n",
       "      <td>-0.038033</td>\n",
       "      <td>2.621636</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.657196</td>\n",
       "      <td>-2.271627</td>\n",
       "      <td>1.324874</td>\n",
       "      <td>-0.097875</td>\n",
       "      <td>3.637970</td>\n",
       "      <td>-3.413761</td>\n",
       "      <td>0.790723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.364217</td>\n",
       "      <td>-1.296612</td>\n",
       "      <td>-0.384658</td>\n",
       "      <td>-0.553006</td>\n",
       "      <td>3.030874</td>\n",
       "      <td>-1.303849</td>\n",
       "      <td>0.501984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Size    Weight  Sweetness  Crunchiness  Juiciness  Ripeness   Acidity  \\\n",
       "0 -3.970049 -2.512336   5.346330    -1.012009   1.844900  0.329840 -0.491590   \n",
       "1 -1.195217 -2.839257   3.664059     1.588232   0.853286  0.867530 -0.722809   \n",
       "2 -0.292024 -1.351282  -1.738429    -0.342616   2.838636 -0.038033  2.621636   \n",
       "3 -0.657196 -2.271627   1.324874    -0.097875   3.637970 -3.413761  0.790723   \n",
       "4  1.364217 -1.296612  -0.384658    -0.553006   3.030874 -1.303849  0.501984   \n",
       "\n",
       "   Target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Target\n",
       "0    1614\n",
       "1    1586\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('Target', axis=True)\n",
    "\n",
    "y = df.Target\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=SEED)\n",
    "y_train.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN                  accuracy\ttrain = 92.69% \ttest = 91.12%\n",
      "KNN(3)               accuracy\ttrain = 94.38% \ttest = 90.25%\n",
      "DT                   accuracy\ttrain = 100.00% \ttest = 79.00%\n",
      "DT(max_depth=5)      accuracy\ttrain = 76.84% \ttest = 74.12%\n",
      "RF                   accuracy\ttrain = 100.00% \ttest = 90.50%\n",
      "\n",
      "After scaling\n",
      "\n",
      "KNN                  accuracy\ttrain = 92.81% \ttest = 91.25%\n",
      "KNN(3)               accuracy\ttrain = 94.06% \ttest = 90.00%\n",
      "DT                   accuracy\ttrain = 100.00% \ttest = 77.88%\n",
      "DT(max_depth=5)      accuracy\ttrain = 76.84% \ttest = 74.00%\n",
      "RF                   accuracy\ttrain = 100.00% \ttest = 90.50%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifiers = {\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"KNN(3)\": KNeighborsClassifier(3),\n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"DT(max_depth=5)\": DecisionTreeClassifier(max_depth=5),\n",
    "    \"RF\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "\n",
    "for name, model in classifiers.items():\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Scoring on SEEN data - effectively \"useless\"\n",
    "    y_pred = model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "    # Scoring on UNSEEN data - important\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{name:20s} accuracy\\ttrain = {train_accuracy:.2%} \\ttest = {test_accuracy:.2%}\")\n",
    "    \n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nAfter scaling\\n\")\n",
    "\n",
    "for name, model in classifiers.items():\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Scoring on SEEN data - effectively \"useless\"\n",
    "    y_pred = model.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_pred)\n",
    "\n",
    "    # Scoring on UNSEEN data - important\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"{name:20s} accuracy\\ttrain = {train_accuracy:.2%} \\ttest = {test_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN                  accuracy\ttrain = 92.69% \ttest = 91.12%\n",
    "KNN(3)               accuracy\ttrain = 94.38% \ttest = 90.25%\n",
    "DT                   accuracy\ttrain = 100.00% \ttest = 79.00%\n",
    "DT(max_depth=5)      accuracy\ttrain = 76.84% \ttest = 74.12%\n",
    "RF                   accuracy\ttrain = 100.00% \ttest = 90.50%\n",
    "\n",
    "After scaling\n",
    "\n",
    "KNN                  accuracy\ttrain = 92.81% \ttest = 91.25%\n",
    "KNN(3)               accuracy\ttrain = 94.06% \ttest = 90.00%\n",
    "DT                   accuracy\ttrain = 100.00% \ttest = 77.88%\n",
    "DT(max_depth=5)      accuracy\ttrain = 76.84% \ttest = 74.00%\n",
    "RF                   accuracy\ttrain = 100.00% \ttest = 90.50%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questões"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pergunta:** Qual é a diferença entre dados de treinamento e dados de teste ao treinar um modelo de classificação?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados de treinamento e os dados de teste são usados ao treinar um modelo de classificação de forma a avaliar o desempenho do modelo em diferentes conjuntos de dados.\n",
    "\n",
    "Os dados de treinamento são usados para treinar o modelo, ou seja, para ajustar os parâmetros do modelo com base nos exemplos fornecidos. O modelo aprende com esses dados e tenta capturar os padrões e relações entre as variáveis de entrada e a variável de saída.\n",
    "\n",
    "Os dados de teste são usados para avaliar o desempenho do modelo em dados não vistos durante o treinamento. Esses dados são usados para medir a capacidade do modelo de generalizar e fazer previsões precisas em novos exemplos. Ao avaliar o modelo com os dados de teste, podemos ter uma ideia de como o modelo se comportará em situações reais.\n",
    "\n",
    "A diferença fundamental entre os dados de treinamento e os dados de teste é que os dados de treinamento são usados para ajustar o modelo, enquanto os dados de teste são usados para avaliar o desempenho do modelo. É importante que os dados de teste sejam independentes e representativos dos dados reais que o modelo encontrará após o treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pergunta:** Com base no dataset fornecido, a abordagem do treinamento do modelo deve ser `supervisionada` ou `não-supervisionada`? Por quê?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base no dataset fornecido, a abordagem do treinamento do modelo deve ser `supervisionada`. Isso ocorre porque o dataset possui uma variável alvo (Target) que indica a classe ou categoria a ser prevista. Nesse tipo de abordagem, o modelo é treinado usando exemplos rotulados, ou seja, cada exemplo no dataset possui uma classe ou categoria associada. O objetivo é aprender um mapeamento entre as variáveis de entrada (Size, Weight, Sweetness, Crunchiness, Juiciness, Ripeness, Acidity) e a variável alvo (Target) para fazer previsões precisas em novos exemplos não vistos durante o treinamento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
